\chapter{Padrões e Tecnologias de Videoconferência}\label{cha:padroes-e-tecnologias}

	Segundo \cite{conferencingFundamentals}, as principais camadas de um sistema de conferência são:
	
	\begin{itemize}
		\item Interface de usuário e de administrador;
		\item Controle de Conferência: controle de criação/finalização de sessões, de roteamento de ligações e de alocações de recursos em geral;
		\item Plano de Controle: controle de chegada/saída de conexões e da negociação de parâmetros da sessão de acordo com a capacidade do servidor de mídia;
		\item Plano de Mídia: controle das \textit{streams} de mídia, administrando o transporte, codificação/decodificação e a mixagem de áudio e vídeo.
	\end{itemize}
	
	O principal desafio para interoperabilidade entre sistemas de videoconferência é considerar os diferentes Planos de Controle e de Mídia existentes. São essas camadas que definem de que maneira um sistema envia e recebe requisições para entrada e saída de usuários, bem como o modo no qual ele irá transmitir e receber áudio e vídeo. Um sistema de conferência com Plano de Controle e de Mídia flexíveis permitem que usuários utilizando diferentes equipamentos ou softwares de videoconferência - os chamados \textit{endpoints} - se conectem e se comuniquem de maneira transparente em uma sessão desse sistema.
	
	Como afirmado em \cite{kurose}, com a popularização das aplicações de tempo real, importantes órgãos, como o IETF e ITU, estabeleceram (e continuam estabelecendo) padrões para essa classe de aplicações. No contexto de videoconferência, padrões amplamente usados no Plano de Controle são os protocolos de sinalização SIP e H.323, os quais veremos na Seção~\ref{sec:sinalização}. Já no Plano de Mídia, dependemos tanto de padrões de transporte como de codificação de mídia (Seções~\ref{sec:transporte} e~\ref{sec:codecs}). Já em termos de webconferência, a tecnologia que compõe o sistema determinará o escopo de padrões usados, como será detalhado na Seção~\ref{sec:tecnologias-webconf}.
	
	A seguir, portanto, são apresentados alguns dos principais padrões e tecnologias para sistemas de conferência.
	

\section{Protocolos de Sinalização}\label{sec:sinalização}

    Os protocolos de sinalização têm como papel a implementação do Plano de Controle. 
    Para isso:
    
    \begin{enumerate}
         \item Determinam-se as portas onde o sistema irá aguardar conexões de \textit{endpoints}. Tais portas definem o \textbf{canal de sinalização} de um sistema de conferência;
         
         \item No momento em que um \textit{endpoint} se conecta no canal de sinalização, o Plano de Controle envia informações da capacidade de mídia do sistema, as quais o \textit{endpoint} deve respeitar. Esse passo estabelece a \textbf{negociação de mídia};
         
         \item Após essa negociação (bem-sucedida), o Plano de Controle e o \textit{endpoint} abrem um canal lógico para \textit{streaming} de mídia, e o \textit{endpoint} passa a se comunicar, então, com o Plano de Mídia, para enviar e/ou receber áudio/vídeo. O Plano de Controle será responsável por administrar esse canal lógico, avisando o Plano de Mídia se o \textit{endpoint} sair da sessão, ou algum erro de conexão ocorrer.
         
    \end{enumerate}
    
     Como dito na introdução desse capítulo, existem dois principais padrões para a sinalização. O primeiro, H.323, foi estabelecido pelo ITU em 1996. O segundo, SIP, foi projetado pelo IETF e primeiramente definido no RFC 2543 em 1999.
     
     
\subsection{Padrão H.323}\label{sec:h.323}
	
     Como afirmado em \cite{tanenbaum}, H.323, mais do que um protocolo específico, é uma visão geral da arquitetura de telefonia da Internet, bem como um encapsulador de diversos outros protocolos (que veremos no decorrer desse trabalho).
     O padrão, primeiramente, define quatro tipos de unidades (ilustrados na Figura~\ref{fig:unidades-h323}):
     
		\begin{itemize}
			  \item \textbf{Terminais}: são os \textit{endpoints}, emissores e receptores de mídia. É a única unidade obrigatória;
			  
			  \item \textbf{\textit{Gatekeeper}}: define a \textit{zona} - conjunto de terminais que o gatekeeper irá administrar -, controlando quais \textit{endpoints} podem se comunicar entre si, provendo acesso e controlando a largura de banda utilizada pelos terminais;
			  
			  \item \textbf{\textit{Gateway}}: permite a interoperação com terminais que utilizam redes de telefonia ou outros tipos de rede (que não a internet). Na prática, ainda permite a interoperabilidade com terminais que utilizem SIP, em vez de H.323, para sinalização;
			  
			  \item \textbf{\textit{MCU}} \textit{(Multipoint Control Unit)}: sistema que permite que múltiplos terminais se conectem em uma sessão de conferência, distribuindo e mixando a mídia para os participantes.
			  
		 \end{itemize}
		 
		 \begin{figure}[h]
			\centering
			\includegraphics[width=24em, height=9em]{img/unidades-h323.png}
			\caption{Unidades H.323.}
			\label{fig:unidades-h323}
		 \end{figure}
		  

     \subsubsection{\textbf{H.225}}\label{sec:h225}
     
      	O protocolo H.225 define o canal de sinalização de uma sessão H.323, descrevendo, portanto, como uma chamada é iniciada, estabelecida e finalizada. 
      	Um terminal iniciando uma chamada (daqui para frente chamado de \textit{caller}), deve, primeiramente, abrir uma conexão TCP com a unidade que se quer chamar (respectivamente, \textit{callee}), que estará esperando conexões na porta 1720. Um pacote H.225 é ilustrado na Figura~\ref{fig:pacote-h225} e é definido da seguinte forma: 
      	
 		 \begin{figure}[h]
 			\centering
 			\includegraphics[width=22em, height=8em]{img/pacote-h225.png}
 			\caption{Pacote H.225.}
 			\label{fig:pacote-h225}
 		 \end{figure}
 		 
 		 \begin{itemize}
 		    \item \textit{Protocol Discriminator}: Número que identifica a mensagem como uma mensagem H.225. O valor desse campo é 8.
 		    \item \textit{Length of Call Reference Value}: comprimento do CRV, que pode ser 1 ou 2 bytes;
 		    \item \textit{Call Reference Value}: CRV é o número identificador único da chamada;
 		    \item \textit{Message Type}: tipo da mensagem que o pacote H.225 carrega (\textit{Setup Message, Connect, Alerting}, etc - definidos mais adiante).
 		    \item \textit{Information Elements}: espaço para parâmetros adicionais. Dependem do \textit{Message Type}.
 		 \end{itemize}
 		 
 		 A Figura~\ref{fig:conexao-h323-basica} demonstra o estabelecimento de uma chamada H.323 básica:
 		 
 		 \begin{figure}[h]
 			\centering
 			\includegraphics[width=29em, height=17.2em]{img/conexao-h323-basica.png}
 			\caption{Estabelecimento de uma chamada H.323 básica.}
 			\label{fig:conexao-h323-basica}
 		 \end{figure}
 		 
 		 \begin{enumerate}
 		    \item Após o estabelecimento da conexão TCP, o caller inicia a chamada, mandando um H.225 \textit{Setup Message}. Esse tipo de \textit{Message Type} carrega como parâmetro obrigatório o \textit{Bearer Capability}, que define a natureza da chamada: se é apenas de áudio ou uma chamada audiovisual.
 		    
 		    \item O \textit{callee} responde o \textit{Setup Message}, com um H.225 \textit{Alerting}, indicando ao \textit{caller} que o dispositivo chamado já iniciou o procedimento de alerta de que uma nova chamada chegou - em outras palavras, que o dispositivo está 'tocando' (como um telefone; em inglês, \textit{Ringing}). Antes do \textit{Alerting}, outro tipo de \textit{Message Type} pode ocorrer (não é obrigatório) do \textit{callee} para o \textit{caller}: o \textit{Call Proceeding}. CP tem o objetivo de informar o \textit{caller} que a chamada está em processo de ser estabelecida.
 		    
 		    \item O \textit{callee} também responde um \textit{Setup ACK}, indicando que o \textit{Setup Message} foi devidamente recebido.
 		    
 		    \item Quando a chamada é finalmente atendida, é mandado um H.225 \textit{Connect} para o \textit{caller}. É nesse momento que a conexão H.225 foi completamente estabelecida.
 		    
 		    \item Mensagens H.225 \textit{Notify} servem para troca de informações gerais entre \textit{caller} e \textit{callee} durante a chamada. Um uso é para o \textit{callee} indicar ao \textit{caller} o seu próprio \textit{Bearer Capability}, como indicado na Figura~\ref{fig:conexao-h323-basica}. 	
 		    
 		    \item Quando uma das partes envolvidas encerra a chamada, é enviado um H.225 \textit{Release Complete}. Com isso, o CRV, identificador único da chamada, é desalocado - assim como quaisquer outros recursos alocados - e pode ser reusado em outra chamada. O H.225 \textit{Release Complete} carrega consigo um código que determina qual foi o motivo do encerramento da chamada (a Recomendação ITU-T H.225.0 \cite{h225-recommendation} contém uma lista de todos os códigos de encerramento e seus significados).		     		    
 		 \end{enumerate}
 		 
      \subsubsection{\textbf{H.245}}\label{sec:h245}
      
         O protocolo H.245 provê o mecanismo para a negociação de mídia e para a abertura dos canais RTP, onde os dados multimídia serão transmitidos/recebidos. Após o H.225 \textit{Setup Message}, o \textit{callee} pode usar o H.225 \textit{Call Proceeding}, \textit{Alerting} ou \textit{Connect} para enviar ao \textit{called} o IP e a porta para a abertura da sessão H.245. Quando o \textit{caller} recebe essas informações, é aberta uma conexão TCP entre as partes envolvidas, onde haverá, então, a negociação de mídia.
      
         A Figura~\ref{fig:negociacao-h323-basica} demonstra como é feita a negociação de mídia via sessão H.245. \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\
      
  		 \begin{figure}[h]
  			\centering
  			\includegraphics[width=26em, height=38em]{img/negociacao-h323-basica.png}
  			\caption{Negociação de mídia H.323.}
  			\label{fig:negociacao-h323-basica}
  		 \end{figure}     
      
  		 \begin{enumerate}
  		    \item Após o estabelecimento da chamada - como visto anteriormente na Seção~\ref{sec:h225} - e da conexão TCP para a Sessão H.245, \textit{caller} e \textit{callee} trocam, primeiramente, 2 tipos de mensagens H.245: \textit{TCS} (\textit{Terminal Capability Set}) e \textit{MSD} (\textit{Master-Slave Determination}).
  		    
  		    \item \textit{TCS} contém a descrição da capacidade de mídia do remetente da mensagem. Inclui a lista de todos os codecs de áudio e vídeo suportados e suas características (tipos de payload, perfis e resoluções de vídeo, taxa de bits e de frames, etc - itens que veremos nas próximas seções). Também contém o \textit{Simultaneous Capability Set}, que define quais grupos de codecs podem ser usados simultaneamente. A parte que recebe o H.245 \textit{TCS} informa ao transmissor da mensagem o recebimento da mesma com um \textit{TCS ACK}.
  		    		 		 
	 		\item A troca de mensagens \textit{MSD} define quem irá ser o 'mestre' e o 'escravo' da sessão. O mestre será responsável por atribuir um ID para o canal lógico, gerar uma chave quando há encriptação de mídia, entre outras tarefas de administração do canal lógico. Uma mensagem \textit{MSD} contém um \textit{Terminal Type} (um número) e um \textit{Determination Number} (número aleatório). Cada parte envolvida compara os números recebidos na mensagem \textit{MSD} com os seus próprios números e quem tiver o maior \textit{Terminal Type} será o mestre. Em caso de empate, o mestre será quem tiver o maior \textit{Determination Number}. Caso haja novamente um empate, ocorre uma nova negociação, com novas mensagens \textit{MSD}.
	 		
	 		\item Posteriormente à determinação do mestre e escravo, o \textit{caller} envia o H.245 \textit{OpenLogicalChannel} (\textit{OLC}), requisitando a abertura do canal lógico. O canal lógico, no contexto H.323, representa o caminho usado para a transmissão de mídia. A mensagem \textit{OLC} carrega consigo o codec de áudio e de vídeo que o \textit{caller} usará na transmissão, bem como as características de cada codec (como explicado no item 2).
	 		Outros dados importantes do H.245 \textit{OLC} são as portas RTCP (mais detalhes na Seção~\ref{sec:rtp}) que serão usadas no contexto RTP e o \textit{LCN} (\textit{Logical Channel Number}), identificador único do canal lógico.
	 		No exemplo da Figura~\ref{fig:negociacao-h323-basica}, tanto o \textit{caller} quanto o \textit{callee} enviam um \textit{OLC} requisitando um canal para transmitir áudio usando o codec G.722, e um outro \textit{OLC} requisitando um canal para transmitir vídeo H.264. \textit{Generic Video Capability}, transportada na mensagem \textit{OLC}, é uma estrutura H.245 específica para informar características do codec H.264.
	 		Existem, ainda, outras mensagens H.245 específicas para controle de vídeo, como o \textit{Flow Control}, usado para reajustar a taxa de bits máxima, e o \textit{Miscellaneous Command}, utilizado para pausar, congelar, avançar a stream de vídeo, bem como fazer outros ajustes, como, por exemplo, alterar a resolução ou a taxa de frames.
	 		
	 		\item Quem recebe o \textit{OLC} deve examinar os detalhes do pedido de abertura do canal lógico, alocar os recursos necessários e responder com um H.245 \textit{OLC ACK}, contendo os IPs e as portas RTP e RTCP que serão usados para receber a mídia.
	 		
	 		\item Quando uma das partes envolvidas encerra a chamada, é enviado um H.245 \textit{Close Logical Channel} (\textit{CLC}), que deverá ser respondido com um \textit{CLC ACK}.
	 		
	 		\item H.245 \textit{End Session} é a mensagem que indica o fim da sessão. Após essa mensagem, não há mais trocas de nenhuma outra mensagem H.245 (portanto, não há ACK para \textit{End Session}).
  		 \end{enumerate}
  		 
      \subsubsection{\textbf{H.323 \textit{Fast Connect Mode}}}\label{sec:h323-fast}
      
         No H.323 versão 2 existe a opção do \textit{Fast Connect Mode} (Figura~\ref{fig:h323-fast}). O \textit{caller} manda um H.245 \textit{OLC} com um codec sugerido dentro do H.225 \textit{Setup Message}. Se o \textit{callee} suportar \textit{Fast Connect Mode} e aceitar a sugestão do codec, será respondido um H.225 \textit{Connect} também transportando um H.245 \textit{OLC}. Com isso, as partes envolvidas já têm as informações necessárias para estabelecer a conexão de mídia, diminuindo significantemente o número de mensagens requeridas para estabelecer a sessão H.323. Segundo \cite{conferencingFundamentals}, equipamentos de vídeo H.323 geralmente não suportam \textit{Fast Connect Mode}. \\
         
 		 \begin{figure}[h]
 			\centering
 			\includegraphics[width=26em, height=18em]{img/h323-fast.png}
 			\caption{H.323 \textit{Fast Connect Mode}.}
 			\label{fig:h323-fast}
 		 \end{figure}        

      \subsubsection{\textbf{Mais informações sobre H.323}}\label{sec:h323-mais infos}
      
         Para mais informações sobre o protocolo H.323, consulte \cite{h225-recommendation}, \cite{h323-recommendation}, \cite{h245-recommendation} e também \cite{conferencingFundamentals}.
    
\subsection{Padrão SIP}\label{sec:sip}
	
	Segundo \cite{tanenbaum}, muitos viam o H.323 como um típico produto de uma companhia de telecomunicação: grande, complexo e inflexível. Nessa situação, o IETF projeta o padrão SIP, que, em vez de uma suíte de protocolos, é um módulo único. O protocolo SIP é \textit{text-based}, apresentando todas as suas mensagens, atributos e métodos em ASCII. 
	 O padrão, primeiramente, define os seguintes elementos:
	
		\begin{itemize}
			  \item \textbf{\textit{User Agent}}: podem ser tanto os \textit{endpoints}, emissores e receptores de mídia, quanto servidores de controle de chamada (abordados nos próximos itens). 
			  Todo \textit{UA} é formado por um \textit{User Agent Client} (\textit{UAC}) - responsável por iniciar as transações (que também definiremos mais adiante)- e por um \textit{User Agent Server} (\textit{UAS}) - responsável pelas respostas dessas transações;
			  
			  \item \textbf{\textit{Proxy Server}}: Entidade que faz o roteamento de mensagens SIP. É responsável por determinar para onde mensagens SIP vão ser direcionadas (quais \textit{endpoints} ou servidores receberão determinada mensagem), provendo também autenticação e autorização de mensagens. Um PS \textit{stateful} armazena o histórico de todas as mensagens de uma transação, a fim de levantar dados para distribuição de sessões SIP em diferentes servidores e/ou para geração de estatísticas. Já um PS \textit{stateless} faz o roteamento de mensagens sem guardar quaisquer informações.
			  
			  \item \textbf{\textit{Redirect Server}}: Entidade que informa UAs para onde uma mensagem SIP deve ser encaminha. Um UA manda uma mensagem SIP, que deve ser entregue a outro UA, para o \textit{Redirect Server}. Este, então, retorna para o UA de origem o endereço alternativo do UA destino. Em posse da nova informação, o UA remetente remanda a mensagem SIP diretamente para o UA destino. Portanto, não é o \textit{Redirect Server} que faz o roteamento da mensagem (como o \textit{Proxy Sever} faria): o trabalho de fazer a nova ligação - utilizando o endereço certo advindo da resposta do RS - é do UA de origem.
			  
			  \item \textbf{\textit{Registrar Server}}: Entidade para onde os usuários enviam o pedido de registro. Usuários são registrados como URIs em um banco de dados, onde cada URI é associado com uma localização (normalmente o endereço IP desse usuário). Com isso, \textit{Proxy Servers} ou \textit{Redirect Servers} podem usar essa base de dados para executar suas tarefas.
		\end{itemize}	
	
	Na Figura~\ref{fig:sip-dialog} abaixo, é demonstrado um diálogo SIP:
	
 		\begin{figure}[h]
 			\centering
 			\includegraphics[width=30em, height=19.5em]{img/sip-dialog.png}
 			\caption{Diálogo SIP.}
 			\label{fig:sip-dialog}
 		\end{figure}
 		
 		\begin{enumerate}
 			\item Começamos com o UA callee recebendo um \textit{INVITE} do UA Caller, para o início de uma chamada. Tipicamente, a porta que define o canal de sinalização SIP é a porta 5060 (podemos encontrar ambientes onde se usa a porta 5070 ou 5061 - esta última para sinalizações encriptadas). Um \textit{INVITE} tem a seguinte estrutura (Figura~\ref{fig:sip-invite}): \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\
 		
			\begin{figure}[h]
			    \centering
			    \adjustbox{margin=1em,width=10.3cm,frame,center}
			    {\begin{minipage}{0.99\linewidth}
			        INVITE sip:UAcallee@172.27.14.53 SIP/2.0 \newline
			        
			        ! As linhas abaixo são os \textit{headers} SIP: \newline
			        Via: SIP/2.0/UDP 172.27.14.4:5060;branch=8dJXAX9MDw \newline
			        Max-Forwards: 70 \newline
			        To: <sip:UAcallee@172.27.14.53> \newline
			        From: <sip:UAcaller@172.27.14.4>;tag=ds17aa9bd4 \newline
			        Call-ID: 11022705439144@172.27.14.4 \newline
			        CSeq: 1 INVITE \newline
			        Allow: INVITE, ACK, CANCEL, OPTIONS, BYE \newline
			        Content-Length: 251 \newline
			        Content-Type: application/sdp \newline
			        
			        ! Já as linhas abaixo estão no \textit{body} do INVITE SIP:\newline 
			        v=0 \newline
			        o=UACaller 1549546120 0 IN IP4 172.27.14.4 \newline
			        s=ExampleSession \newline
			        c=IN IP4 172.27.14.4 \newline
			        t=0 0 \newline
			        m=audio 49220 RTP/AVP 118 \newline
			        a=rtpmap:118 Speex/16000/1 \newline
			        m=video 5068 RTP/AVP 104 \newline
			        a=rtpmap:104 H264/90000 \newline
			        a=fmtp:104 max-fs=6336;max-mbps=190080;profile-level-id=42801e
			    \end{minipage}}
			    \caption{SIP Invite.}
			    \label{fig:sip-invite}
			\end{figure}
			
			O INVITE é acompanhado do endereço de destino (no caso, o usuário 'UAcalle' que está no endereço IP 172.27.14.53) e tem os seguintes cabeçalhos:
			
			\begin{enumerate}
			   \item \textit{Via}: indica como transportar a mensagem (no caso, usando UDP) e para onde as respostas dessa mensagem devem ir (IP e porta de destino). Ainda contém o \textit{branch}, identificador único da transação SIP. Uma transação, no contexto SIP, significa um \textit{Request} - requisição - seguido de suas \textit{Responses} - respostas (pode ser visto na Figura~\ref{fig:sip-dialog} que o ACK não está incluído na Transação 1, isso pois, em geral, ACK não é considerado parte de transações). Já um diálogo SIP é o conjunto de todas as transações entre 2 UAs. Nas Tabelas~\ref{tab:sip-requests} e~\ref{tab:sip-responses} são definidos os SIP \textit{Requests} e os SIP \textit{Responses} mais comuns segundo \cite{conferencingFundamentals};		   
			  
			   \begin{table}[h]
				\begin{center}
				 \resizebox{15.5cm}{!} {
				    \begin{tabular}{| c | l |}    \hline
				    \textbf{SIP Request} & \textbf{Descrição}   \\ \hline \hline
				    INVITE &  Convida um UA para uma chamada.     \\ \hline
				    BYE & Termina o diálogo SIP entre 2 UAs.       \\ \hline
				    OPTIONS & Solicita informações das capacidades do UA remoto.      \\ \hline
				    MESSAGE & Manda mensagens instantâneas (não faz parte de um diálogo).     \\ \hline
					ACK & \makecell[l]{Confirma que o UA \textit{caller} recebeu uma \textit{Response} \\ definitiva (que não é da classe \textit{1xx}) sobre o seu pedido de INVITE.}     \\ \hline
				    REGISTER & Solicitação para ser registrado em um servidor de registro.       \\ \hline
				    CANCEL & Cancela um \textit{Request} corrente.       \\ \hline
				    INFO & Método para UAs trocarem informações gerais durante uma sessão SIP.       \\ \hline
				    PRACK & \makecell[l]{Age como um ACK temporário, onde um UA confirma que recebeu \\ alguma \textit{Response} provisória (da classe \textit{1xx})}       \\ \hline
				    UPDATE & Atualiza o estado da sessão SIP.      \\ \hline
				    SUBSCRIBE & \makecell[l]{Solicita inscrição para receber notificações da ocorrência de \\ determinado(s) evento(s) SIP.}      \\ \hline
				    NOTIFY & Envia um evento de notificação para UAs inscritos.     \\ \hline
				    REFER & \makecell[l]{Indica que um UA deve usar o endereço contido no REFER para refazer um \\ determinado \textit{Request}.}      \\ \hline
				    \end{tabular}}
					\caption{SIP Requests.}
					\label{tab:sip-requests}
				 \end{center}
				\end{table}
				

			   \begin{table}[h]
				\begin{center}
				    \begin{tabular}{| c | c | c |}    \hline
				    \textbf{SIP Response Code} & \textbf{Reason} & \textbf{Response Class}  \\ \hline \hline
				    100 & Trying & 1xx     \\ \hline
				    180 & Ringing & 1xx       \\ \hline
				    200 & OK & 2xx      \\ \hline
				    301 & Moved permanently & 3xx     \\ \hline
					302 & Moved temporarily & 3xx      \\ \hline
				    400 & Bad Request & 4xx       \\ \hline
				    600 & Busy & 6xx       \\ \hline
				    603 & Decline & 6xx       \\ \hline
				    604 & Does not exist & 6xx       \\ \hline				    				 
				    \end{tabular}
					\caption{SIP Responses.}
					\label{tab:sip-responses}
				 \end{center}
				\end{table}
			   
			   
			   \item \textit{Max-Forwards}: usado para evitar \textit{loops}. Toda vez que um \textit{Request} é redirecionado, o \textit{proxy} que recebe esse \textit{Request} decrementa o \textit{Max-Forwards} em 1. Se um \textit{proxy} recebe um \textit{Request} com \textit{Max-Forwards} igual a 0, ele responde com uma mensagem de erro para o UA de origem;
			   
			   \item \textit{To}: identificador do destino: usuário seguido do seu endereço IP;
			   
			   \item \textit{From}: identificador da origem: usuário seguido do seu endereço IP. O parâmetro \textit{tag} é usado para identificar o diálogo SIP;
			   
			   \item \textit{Call-ID}: identificador único da chamada SIP;
			   
			   \item \textit{Cseq}: o \textit{Command Sequence} é um identificador de transação, sendo um número (que pode ser arbitrário) acompanhado do nome da \textit{Request} que originou a transação. Todas as \textit{Requests} e \textit{Responses} de uma transação devem usar o mesmo \textit{Cseq};
			   
			   \item \textit{Allow}: lista de \textit{Requests} que o UA pode enviar e receber;
			   
			   \item \textit{Content-Length}: número de caracteres do \textit{body}; 
			   
			   \item \textit{Content-Type}: do que consiste o body; no caso, do SDP.
			   
			\end{enumerate}
			
			O SDP (\textit{Session Description Protocol}) define a sintaxe da descrição da sessão SIP de mídia. É através da troca de SDPs entre origem e destino que é feita a negociação de mídia.	
			No exemplo da Figura~\ref{fig:sip-invite}, o SDP contém os seguintes parâmetros:
			\begin{enumerate}
				\item \textit{v}: versão do SDP;
				\item \textit{o}: identificador do criador da sessão;
				\item \textit{s}: nome da sessão;
				\item \textit{c}: informação da conexão. Basicamente, de qual IP virá a mídia. Esse é um exemplo de atributo que pode ser tanto: 
				      \begin{itemize}
				         \item \textit{session-level}: vale para toda a sessão. Para isso, o atributo deve estar listado antes da descrição das mídias. No exemplo da Figura~\ref{fig:sip-invite}, o parâmetro \textit{"c="} está justamente como atributo de sessão, ou seja, todas as mídias que serão descritas posteriormente virão do mesmo IP;
				         
				         \item \textit{media-level}: vale apenas para uma mídia específica. Para isso, o atributo deve estar listado depois de uma descrição de mídia (\textit{"m="}). Com isso, por exemplo, poderíamos declarar diferentes informações da conexão para diferentes mídias (assim, áudio e vídeo poderiam vir de IPs distintos).
				      \end{itemize}
				      
				\item \textit{t}: define o tempo de início e o tempo de fim da sessão SIP. Os valores de \textit{t} são representações decimais dos valores de tempo do \textit{Network Time Protocol} (NTP), que, por sua vez, são os valores de tempo em segundos desde 1900. No exemplo da Figura~\ref{fig:sip-invite}, ambos os valores são zero, significando que o começo da sessão é imediato (assim que negociação de mídia terminar) e sem tempo de término (sessão só será encerrada quando uma das partes envolvidas desligar a chamada);
				
				\item \textit{m}: descreve as mídias que serão usadas. No nosso exemplo, tanto áudio, quanto vídeo. A linha \textit{"m="} ainda define a porta de destino da mídia (49220 para áudio e 5068 para vídeo), o protocolo de transporte usado na transmissão da mídia (RTP para ambos) e a lista de \textit{payload types} (Seção~\ref{sec:rtp}) de cada codec de mídia;
				
				\item \textit{a}: descrição de um atributo. Atributos podem ser \textit{session-level} (atributos de sessão) ou \textit{media-level} (atributos de mídia).
				Um uso importante desse parâmetro é descrever os codecs de mídia que um UA suporta, logo após a descrição de mídia (\textit{"m="}). Na Figura~\ref{fig:sip-invite}, é estabelecido que o UACaller só suporta Speex como codec de áudio e H.264 como codec de vídeo. Ao final do SDP, há ainda alguns atributos específicos do codec H.264, como tamanho máximo de frame, taxa máxima de bits por segundo e \textit{profile} de vídeo (ver Seção~\ref{sec:codecs}). Vale a menção que há diversos outros usos para atributos e existe uma lista extensa definida em \cite{sip-rfc}.
			\end{enumerate}
			
			\item Quando o \textit{callee} recebe a chamada e entra em processo para determinar se a aceitará ou não, é mandado um 100 Trying para o \textit{caller} (Figura~\ref{fig:sip-trying}):
			
			\begin{figure}[h]
			    \centering
			    \adjustbox{margin=1em,width=10.3cm,frame,center}
			    {\begin{minipage}{0.9\linewidth}
			        SIP/2.0 100 Trying \newline \newline
			        Via: SIP/2.0/UDP 172.27.14.53:5060;branch=8dJXAX9MDw \newline
			        To: <sip:UAcaller@172.27.14.4> \newline
			        From: <sip:UAcallee@172.27.14.53>;tag=ds17aa9bd4 \newline
			        Call-ID: 11022705439144@172.27.14.4 \newline
			        CSeq: 1 INVITE \newline
			        Content-Length: 0
			    \end{minipage}}
			    \caption{SIP 100 Trying.}
			    \label{fig:sip-trying}
			\end{figure}
			
			\item Assim que o \textit{callee} aceita a chamada, este manda um 200 OK para o \textit{caller} (Figura~\ref{fig:sip-ok}). Nele, há o SDP descrevendo quais codecs de mídia, do conjunto que o \textit{caller} enviou no SDP do INVITE, que o \textit{callee} também suporta (no caso, o \textit{callee} também suporta Speex e H.264). Há também, como importante atributo de mídia (tanto para áudio, quanto para vídeo), o IP e as portas RTCP que o \textit{callee} usará para o controle do recebimento dos fluxos RTP (áudio e vídeo).
			\newline		
			\begin{figure}[h]
			    \centering
			    \adjustbox{margin=1em,width=10.3cm,frame,center}
			    {\begin{minipage}{1.05\linewidth}
			        SIP/2.0 200 OK \newline
			        
			        Via: SIP/2.0/UDP 172.27.14.53:5060;branch=8dJXAX9MDw \newline
			        To: <sip:UAcaller@172.27.14.4> \newline
			        From: <sip:UAcallee@172.27.14.53>;tag=ds17aa9bd4 \newline
			        Call-ID: 11022705439144@172.27.14.4 \newline
			        CSeq: 1 INVITE \newline
			        Content-Length: 317 \newline
			        Content-Type: application/sdp \newline
			        
			        v=0 \newline
			        o=UACaller 1549568353 0 IN IP4 172.27.14.53 \newline
			        s=ExampleSession \newline
			        c=IN IP4 172.27.14.53 \newline
			        t=0 0 \newline
					m=audio 31818 RTP/AVP 118 \newline
					a=rtpmap:118 Speex/16000 \newline
					a=rtcp:31819 IN IP4 172.27.14.53 \newline
					m=video 29240 RTP/AVP 104 \newline
					a=rtpmap:104 H264/90000 \newline
					a=fmtp:104 max-fs=6336;max-mbps=190080;profile-level-id=42801e \newline
					a=rtcp:29241 IN IP4 172.27.14.53			           
			    \end{minipage}}
			    \caption{SIP 200 OK.}
			    \label{fig:sip-ok}
			\end{figure}			
				
			\item Quando o \textit{caller} finalmente recebe o 200 OK, ele transmite o ACK (Figura~\ref{fig:sip-ack}). A partir daí, ambos os UAs estão numa chamada estabelecida e prontos para enviarem e receberem áudio e vídeo.

			\begin{figure}[h]
			    \centering
			    \adjustbox{margin=1em,width=10.3cm,frame,center}
			    {\begin{minipage}{1.05\linewidth}
			        ACK sip:UAcallee@172.27.14.53 SIP/2.0 \newline
			        
			        Via: SIP/2.0/UDP 172.27.14.4:5060;branch=8dJXAX9MDw \newline
			        Max-Forwards: 70 \newline
			        To: <sip:UAcallee@172.27.14.53> \newline
			        From: <sip:UAcaller@172.27.14.4>;tag=ds17aa9bd4 \newline
			        Call-ID: 11022705439144@172.27.14.4 \newline
			        CSeq: 1 ACK \newline
			        Content-Length: 0
			    \end{minipage}}
			    \caption{SIP ACK.}
			    \label{fig:sip-ack}
			\end{figure}			
			
			\item Quando uma das partes desliga a chamada, é enviado um BYE (Figura~\ref{fig:sip-bye}). No caso da Figura~\ref{fig:sip-invite}, quem o faz é o \textit{callee}: 
			
			\begin{figure}[h]
			    \centering
			    \adjustbox{margin=1em,width=10.3cm,frame,center}
			    {\begin{minipage}{1.05\linewidth}
			        BYE sip:UAcaller@172.27.14.4 SIP/2.0\newline
			        
			        Via: SIP/2.0/UDP 172.27.14.53:5060;branch=8dJXAX9MDv \newline
			        To: <sip:UAcaller@172.27.14.4> \newline
			        From: <sip:UAcallee@172.27.14.53>;tag=ds17aa9bd4 \newline
			        Call-ID: 11022705439144@172.27.14.4 \newline
			        CSeq: 5 BYE \newline
			        Content-Length: 0
			    \end{minipage}}
			    \caption{SIP BYE.}
			    \label{fig:sip-bye}
			\end{figure}			
			
			\item No momento em que o \textit{caller} recebe o BYE, é enviado o 200 OK (Figura~\ref{fig:sip-ok-final}) para o \textit{callee} e, desse modo, a chamada é encerrada.
			\newline \newline
			
			\begin{figure}[h]
			    \centering
			    \adjustbox{margin=1em,width=10.3cm,frame,center}
			    {\begin{minipage}{1.05\linewidth}
			        SIP/2.0 200 OK \newline
   
			        Via: SIP/2.0/UDP 172.27.14.4:5060;branch=8dJXAX9MDv \newline
			        Max-Forwards: 70 \newline
			        To: <sip:UAcallee@172.27.14.53> \newline
			        From: <sip:UAcaller@172.27.14.4>;tag=ds17aa9bd4 \newline
			        Call-ID: 11022705439144@172.27.14.4 \newline
			        CSeq: 5 BYE \newline
			        Content-Length: 0
			    \end{minipage}}
			    \caption{SIP 200 OK.}
			    \label{fig:sip-ok-final}
			\end{figure}			
 		\end{enumerate}		
	
      \subsubsection{\textbf{Mais informações sobre SIP}}\label{sec:sip-mais infos}
      
         Para mais informações sobre o protocolo SIP, consulte \cite{sip-rfc} e \cite{conferencingFundamentals}.




\section{Protocolos de Transporte de Mídia em Tempo Real}\label{sec:transporte}

    Assim que os canais de mídia são estabelecidos através do Plano de Controle (durante as negociações H.323 ou SIP), é função do Plano de Mídia de uma conferência administrá-las, controlando como áudio e o vídeo serão transmitidos/recebidos e como serão tocados em um \textit{endpoint}. Padrões específicos para o transporte de mídia em tempo real são necessários, visto que essa tarefa necessita de certos controles que protocolos de transporte comuns, como UDP e TCP, não oferecem. Neste trabalho, veremos dois desses padrões. O primeiro, RTP, definido no RFC 3550, é o protocolo de transporte em tempo real mais utilizado em aplicações multimídias atualmente. O segundo, RTMP, é o protocolo de transporte em tempo real da Adobe, usado em aplicações multimídias que utilizam a tecnologia Flash.
    
\subsection{Padrão RTP}\label{sec:rtp}
	
	RTP - \textit{Real-Time Protocol} - é um protocolo de nível de aplicação e, no contexto de videoconferência, é o principal padrão para a transmissão de áudio e vídeo em tempo real. O protocolo possui propriedades que auxiliam na fluidez da streaming, na sincronização e nos ajustes de qualidade e de taxa de transmissão de mídias.
	Um pacote RTP é composto pelo cabeçalho mais o pedaço da mídia a ser transmitido. O envio de pacotes RTP é através de um \textit{socket} UDP, portanto todo pacote RTP é encapsulado em um segmento UDP.	
	O cabeçalho é ilustrado na Figura~\ref{fig:rtp-pacote} e tem a seguinte estrutura:
	
 		 \begin{figure}[h]
 			\centering
 			\includegraphics[width=22em, height=9em]{img/rtp-pacote.png}
 			\caption{Pacote RTP.}
 			\label{fig:rtp-pacote}
 		 \end{figure}	
 		 
   Destacam-se os seguintes campos no cabeçalho RTP:
   
   \begin{itemize}
   	 \item \textit{M}: é um bit de marcação. Muito usado para informar que o pedaço de áudio sendo transmitido é o começo de uma fala ou que é o início de um \textit{frame}, caso o pacote RTP esteja transportando vídeo;
   	 
   	 \item \textit{Payload Type}: indica qual algoritmo de codificação de mídia está sendo usado. Existem tanto algoritmos que possuem valores fixos de \textit{Payload Type} (por exemplo, para G.722 - um tipo de codificação de áudio - o \textit{Payload Type} é sempre 9), quanto os que possuem valores dinâmicos (que é o caso do H.264, citado nas seções anteriores), que tipicamente variam de 97 a 127. O valor do PT pode ser alterado no meio de uma transmissão de mídia, e dessa forma o receptor saberá que o algoritmo de codificação mudou. A seguir, mostramos alguns codecs e seus RTP \textit{Payload Types} (Tabela~\ref{tab:rtp-payload-types}): 
   	 
 			   \begin{table}[h]
 				\begin{center}
 				 %\resizebox{15.5cm}{!} {
 				    \begin{tabular}{| c | c | c |}    \hline
 				    \textbf{Codec} & \textbf{Tipo} & \textbf{Payload Type}   \\ \hline \hline
 				    PCMU  &  Áudio &   0   \\ \hline
 				    PCMA &  Áudio &   8   \\ \hline
 				    G.722 &  Áudio &   9   \\ \hline
 				    Speex &  Áudio &   Dinâmico   \\ \hline
 				    OPUS &  Áudio &   Dinâmico   \\ \hline
 				    H.261 &  Vídeo &  31    \\ \hline
 				    H.263 &  Vídeo &  34    \\ \hline
 				    H.264 &  Vídeo &  Dinâmico    \\ \hline
				    VP8 &  Vídeo &  Dinâmico    \\ \hline			    
 				    \end{tabular} %}
 					\caption{RTP Payload Types.}
 					\label{tab:rtp-payload-types}
 				 \end{center}
 				\end{table}  	 
   	 
   	 \item \textit{Sequence Number}: é um contador de pacotes. A cada novo pacote RTP gerado, o \textit{Sequence Number} é incrementado em 1. Assim, o receptor dos pacotes consegue identificar quais pedaços de mídia foram perdidos ou estão atrasados e restaurar a ordem correta desses.
   	 
   	 \item \textit{Timestamp}: Número que define o instante de tempo em que o pacote RTP foi construído. O \textit{Timestamp} dita o ritmo de utilização da mídia (de quanto em quanto tempo um pedaço de mídia deve ser tocado em um player, por exemplo) e ele existe pois o ritmo de recebimento dos pacotes (de quanto em quanto tempo um pedaço de mídia chega no receptor) dificilmente coincide com o de utilização.
   	    	 
   	 \item \textit{Synchronization Source Identifier}: O \textit{SSRC} é o identificador único da stream de mídia. Com isso, o receptor sabe a qual \textit{stream} o pacote recebido pertence.
   	 
   	 \item \textit{Contributing Source Identifiers}: O \textit{CSRC} é a lista de identificadores que contribuíram na construção do conteúdo do pedaço de mídia que o pacote RTP carrega. Com esse campo RTP, é possível adicionar um mecanismo de mixagem em uma sessão, que é uma das tarefas do Plano de Mídia. Por exemplo, numa conferência de múltiplos usuários, um \textit{mixer} receberá os pacotes de áudio dos vários participantes da sessão, e mixará cada \textit{stream} de forma que cada um dos participantes receberá de volta pacotes com o áudio composto dos outros usuários (nessa composição, só não haverá o áudio do próprio participante, para ele não ouvir a si mesmo junto dos outros). Quantos identificadores existem na lista \textit{CSRC} é definido no campo \textit{CC} (\textit{CSRC count}), localizado no começo do cabeçalho RTP.  	 	 
   \end{itemize}
   
   \subsubsection{\textbf{RTCP}}\label{sec:rtp-rtcp}
   
		O RTCP - \textit{RTP Control Protocol} - é o protocolo que atua junto ao RTP. Tem como principal função fornecer aos usuários \textit{feedback} sobre atrasos de pacotes e suas variações, uso e congestionamento de banda, e outras propriedades da rede. Também pode atuar em sincronização de mídia, nomeações de \textit{streams} e identificação de participantes. RTP e RTCP atuam em portas diferentes, a fim da identificação do que é um dado de mídia (no contexto de videoconferência), e o que é um dado de controle.
		
		Tais \textit{feedbacks} são úteis para adaptações nas transmissões. Se pacotes RTCP indicam que a rede não está enfrentando nenhum problema, o transmissor da mídia tem a oportunidade de, por exemplo, trocar para algum codec que ofereça mais qualidade mas que ocupe mais banda, ou simplesmente, utilizando o mesmo codec, elevar a taxa de transmissão a fim de aumentar a qualidade da mídia. Da mesma forma, caso o transmissor receba informações RTCP que apontam problemas na rede, é possível diminuir o uso de banda, alterando codecs e taxas de transmissão (o que provavelmente irá diminuir a qualidade da mídia). O uso alternado e \textit{on-the-fly} de codecs durante a sessão é possível modificando o \textit{Payload Type} dos pacotes RTP (antes do momento efetivo da troca, há nova negociação de mídia SIP ou H.323).		
		
		\textit{Feedbacks} RTCP também são úteis para geração de relatórios que apontam dados importantes como porcentagem de pacotes perdidos, flutuação da qualidade da mídia durante o andamento da sessão, entre outros.
		
		Uma questão envolvendo RTCP é o uso de banda pelo próprio. Pacotes RTCP são enviados para todos os participantes de uma sessão, de forma que o aumento do grupo de usuários pode também levar a um rápido crescimento do uso de banda pelo protocolo RTCP. Diminuir a taxa de envio de \textit{feedbacks} de forma que o envio de mensagens RTCP não ocupe mais que 5 \% da banda é a norma para evitar tal situação. \\
		
   Para mais informações sobre RTP e RTCP, consulte \cite{schulz}.
   
 		 
\subsection{Padrão RTMP}\label{sec:rtmp}
	
	\textit{Adobe's Real Time Messaging Protocol} (RTMP) é o protocolo de transporte usado para \textit{streaming} de áudio, vídeo e outros tipos de dados da plataforma Flash. Inicialmente um padrão proprietário da Macromedia, a Adobe - assim que comprou	a empresa - tornou a especificação do padrão pública, visando a interoperação de outros sistemas com seus produtos.
	Mensagens RTMP são utilizadas somente no nível de aplicação e, diferentemente de RTP - que roda sobre UDP - pacotes RTMP são enviados através de uma conexão TCP, normalmente usando a porta 1935.
	Uma mensagem RTMP é formada pelo cabeçalho e pelo pedaço de mídia a ser transmitido (no contexto de videoconferência). O cabeçalho de uma mensagem RTMP deve conter:
	
	\begin{itemize}
	   \item \textit{Timestamp};
	   \item \textit{Length}: tamanho do \textit{payload} (que contém os dados de mídia);
	   \item \textit{Type Id}: tipo da mensagem que o pacote RTMP carrega. Define se o conteúdo é áudio (\textit{Type Id} = 8), vídeo (\textit{Type Id} = 9), ou controle (há um conjunto de \textit{Type Ids} específicos para o controle de \textit{streaming}).
	   \item \textit{Message Stream ID}: número arbitrário que define o identificador único da \textit{stream}.
	\end{itemize}
	
	Após a montagem da mensagem, ele sofre o processo de \textit{chunking}, onde a mensagem é fragmentada em pedaços menores, os \textit{chunks}. \textit{Chunks} possuem cabeçalho e \textit{payload} variáveis, diminuindo, assim, o \textit{overhead} gerado por pacotes de tamanho fixo (pequenos dados a serem transmitidos em pacotes de tamanho fixo às vezes devem preencher o payload ou cabeçalhos com \textit{dummy bits} apenas para respeitar o tamanho fixo ; assim, parte do pacote a ser transmitido é inútil, e, desse modo, se usa mais banda que o necessário). O receptor, por sua vez, agrupa os \textit{chunks} de uma mesma mensagem através do \textit{Chunk Stream Id}, campo do cabeçalho do \textit{chunk}, montando, assim, a mensagem original. \\	
      
   Para mais informações sobre o protocolo RTMP, consulte \cite{adobe}.
		


\section{Codificação de Mídia}\label{sec:codecs}

    Para diminuir o uso de banda da transmissão de mídia, áudio e vídeo sofrem um processo de compressão antes de serem encapsulados em pacotes RTP ou RTMP. As características de um algoritmo de compressão determinam uma maior ou menor redução de dados, bem como ditam o quanto a mídia perderá qualidade no processo de compressão. Codificação/decodificação - \textit{codec} - (comprimir e descomprimir), pode ser feito tanto em software quanto em hardware, de forma que sistemas de videoconferência de sala tendem a levar vantagem no desempenho dessa tarefa, devido ao seu hardware dedicado. Codecs são \textit{lossy} quando a compressão provoca perda de dados, ou, caso contrário, \textit{lossless}.
    
    Um parâmetro de codificação importante - tanto para áudio quanto para vídeo - é a taxa de bits ou \textit{bitrate}, que define quantos bits são processados para reproduzir uma unidade de tempo da mídia. Por exemplo, se uma compressão de áudio gera uma taxa de 1kbps, a cada 1 segundo de áudio há 1000 bits. Assim, a taxa de bits de uma codificação impacta o tamanho total da mídia (e, consequentemente, o uso da banda para transmiti-la), sua qualidade (em geral, quanto mais bits por unidade de tempo, mais fiel a codificação é à mídia original - embora haja codecs de baixo \textit{bitrate} e boa qualidade), e seu processamento (quanto menor a taxa de bits, maior é a demanda da compressão para reduzir a mídia). Uma codificação pode gerar uma taxa de bits constante (CBR - \textit{Constant bitrate}) ou variável (VBR - \textit{Variable bitrate}).
    
    Para áudio, podem ser destacados outros parâmetros e características, como:
    
    \begin{itemize}
	 	\item Taxa de amostragem (ou \textit{sample rate}): o codec pode alterar o \textit{sample rate} (número de amostras por segundo usado na captura do áudio original), determinando um novo espectro frequências do áudio e impactando na qualidade. No contexto de videoconferência, codecs usam \textit{sample rates} que variam de 8kHz a 48kHz;
	 	
	 	\item Supressão de silêncio - \textit{silence suppression} ou \textit{Voice Activity Detection} (\textit{VAD}): o codec pode detectar silêncios no áudio e descartar os dados, reduzindo o tamanho da mídia;
	 	
	 	\item Cancelamento de eco: o codec pode detectar ecos (geralmente causados por microfones que acabam capturando a saída de alto-falantes e remandando o áudio que havia chegado para outros participantes) e os cancelar;
    \end{itemize}
  
    Já para vídeo, aponta-se:
    
    \begin{itemize}
	 	\item Quadros por segundos (FPS - \textit{frames per second}): número de imagens que serão exibidas no intervalo de 1 segundo. Quanto maior o FPS, maior a fluidez do vídeo e maior uso de banda em transmissão (é uma relação linear: dobrando o FPS, dobra-se a ocupação da banda);
	 	
	 	\item Resolução: largura e altura (em pixels) dos quadros que compõe o vídeo. Resoluções conhecidas são SD (720x480), HD (1280x720) e Full-HD (1920x1080). Possui relação quadrática com o uso de banda, de forma que dobrar a resolução (aumentar a largura e comprimento cada um em duas vezes) quadruplica a ocupação da banda;
	 	
	 	\item Perfil ou \textit{profile}: define um conjunto de características que limita a complexidade da codificação, e, consequentemente, reduz a demanda da decodificação. Por exemplo, alguns perfis podem proibir o uso de \textit{B-Frame} (quadro que tem alta compressão, pois usa informações de quadros anteriores e próximos), pois estes demandam mais processamento e uso de memória;
	 	
	 	\item \textit{Level}: define limitações numéricas de parâmetros, como resolução, \textit{fps}, \textit{bitrate}, etc.
    \end{itemize}

    A seguir, veremos resumidamente alguns padrões populares e/ou atuais usados para a codificação de áudio e vídeo em sistemas de videoconferência:
      
\subsection{Padrões para Codificação de Áudio}\label{sec:codecs-audio}

    			
	\subsubsection{\textbf{Padrão G.7xx}}\label{sec:g7xx}
		
		Codecs da família G.7xx (ou G Series) são padrões ITU-T. 
		
		O origem do G Series se deu em 1972, com o lançamento do padrão G.711, formalmente conhecido como \textit{Pulse Code Modulation} (PCM) \textit{of Voice Frequencies}. Foi primeiramente usado em telefonia, onde existiam 2 versões: o G.711 $µ$-law (ou PCMU), usado em redes de telefonia dos Estados Unidos e Japão, e o G.711 A-law (ou PCMA) usado na Europa e internacionalmente \cite{tanenbaum}. Ainda houve melhorias, como o G.711.0, que gerava compressão sem perdas (\textit{lossless}) e como o G.711.1, que incrementava a qualidade do áudio (bem como o uso de banda). O suporte de G.711 é obrigatório em sistemas H.323.
		
		A Tabela~\ref{tab:g-series} mostra os \textit{bitrates} e a qualidade de alguns codecs G.7xx \cite{speech}. A qualidade foi medida usando MOS, popular tipo de medida subjetiva de qualidade de áudio, classificando-a de 1 a 5 (MOS não será abordado nesse trabalho). Nessa tabela se observa que, no geral, a evolução da G Series apresentou uma taxa de compressão cada vez maior (diminuindo o \textit{bitrate} a cada nova versão, exceto nas versões G.727 e G.728), enquanto manteve o nível de qualidade (exceto pelo G.723.1, em que, comparado à versão anterior deste, diminuiu-se bruscamente o \textit{bitrate}).
		
		Mais informações sobre G.7xx é possível acessando \textit{ITU-T G Series: Transmission systems and media, digital systems and networks}\footnote{\url{http://www.itu.int/net/itu-t/sigdb/speaudio/Gseries.htm}}, página web da ITU-T dedicada a G Series, contendo todas as especificações. \\ \\ \\ \\
		
		
		
 			   \begin{table}[h]
 				\begin{center}
 				 %\resizebox{6.7cm}{!} {
 				    \begin{tabular}{| c | c | c |}    \hline
 				    \textbf{Codec} & \textbf{Bitrate (kbps)} & \textbf{Qualidade}   \\ \hline \hline
 				    G.711       &  64           &   4.3   \\ \hline
 				    G.721/G.726 &  16,24,32,40  &   4.1   \\ \hline
 				    G.722       &  32           &   4.1    \\ \hline
				    G.722.1     &  32           &   4.1    \\ \hline	
				    G.722.2     &  32           &   4.1    \\ \hline
 				    G.723.1     &  5.3 até 6.3  &   3.7 até 3.9   \\ \hline
 				    G.727       &  8            &   4.3   \\ \hline
 				    G.728       &  16           &   4.0   \\ \hline
 				    G.729       &  8            &   4.3    \\ \hline
 				    G.729A      &  8            &   4.3    \\ \hline		    
 				    \end{tabular} %}
 					\caption{Comparação G Series.}
 					\label{tab:g-series}
 				 \end{center}
 				\end{table} 	
		
		
		
	\subsubsection{\textbf{Padrão Speex e Padrão OPUS}}\label{sec:speex-opus}
		
		Speex e OPUS são dois padrões da fundação Xiph.Org\footnote{\url{https://www.xiph.org/about/}}, organização sem fins lucrativos que desenvolve padrões de software open source. 
		
		Speex tornou-se um padrão IETF no RFC 5574\footnote{\url{https://tools.ietf.org/html/rfc5574}} e se baseia no algoritmo de compressão CELP (\textit{Code-Excited Linear Prediction}). Algumas características do Speex são \cite{speex}:
		
		\begin{itemize}
		   \item \textit{Lossy};
		   \item \textit{Sample rate} de 8, 16 ou 32 kHz;
		   \item \textit{Bitrate} variando de 2.15 a 44.2 kbps;
		   \item VBR;
		   \item Cancelamento de eco, supressão de ruído e de silêncio.
		\end{itemize}
		
		Em 2012, surge o OPUS, como uma espécie de 'sucessor' do Speex (o próprio speex.org\footnote{\url{https://www.speex.org}} declara na sua home page: "The Speex codec has been obsoleted by Opus. It will continue to be available, but since Opus is better than Speex in all aspects, users are encouraged to switch."), incorporando características do CELT (outro codec de áudio da Xiph.Org) e SILK (codec de áudio utilizado no Skype).
		
		OPUS tornou-se um padrão IETF no RFC 6716\footnote{\url{https://tools.ietf.org/html/rfc6716}} e é o principal codec de áudio da tecnologia WebRTC (Seção~\ref{sec:webrtc}), conseguindo baixos \textit{bitrates} e alta qualidade. 
		O desenvolvimento do OPUS recebeu colaborações de programadores associados ao Xiph.Org e ao Skype.
		
		OPUS apresenta algumas features como \cite{opus}:		
		\begin{itemize}
		   \item \textit{Lossy};
		   \item \textit{Sample rate} de 8 a 48 kHz;
		   \item \textit{Bitrate} variando de 6 a 510 kbps;
		   \item Suporta tanto VBR quanto CBR;
		\end{itemize}
		
		O opus-codec.org\footnote{\url{http://opus-codec.org/comparison/}} oferece uma página de comparações entre OPUS e outros codecs de áudio. O gráfico abaixo (Figura~\ref{fig:opus-qualidade}), mostra a relação de \textit{bitrate} e qualidade de áudio em diversos codecs:
		
 		 \begin{figure}[h]
 			\centering
 			\includegraphics[width=22em, height=25em]{img/opus-qualidade.png}
 			\caption{OPUS vs outros codecs de áudio.}
 			\label{fig:opus-qualidade}
 		 \end{figure}				
	    
	\subsubsection{\textbf{Padrão iLBC e Padrão iSAC}}\label{sec:ilbc-isac}
		
	\textit{Internet Low Bitrate Codec} (iLBC) e \textit{internet Speech Audio Codec} (iSAC) são codecs de áudio desenvolvidas pela Global IP Solutions, comprada pela Google em 2011, sendo utilizados no Google Hangout e posteriormente incorporados ao WebRTC.
	
	Segundo o overview da arquitetura do WebRTC\footnote{\url{https://webrtc.org/architecture/}}, iSAC apresenta \textit{sample rate} de 16 ou 32 kHz, com um \textit{bitrate} variável de 12 a 52 kbps.
	
	Já iLBC tornou-se padrão IETF, e é definido nos RFCs 3951 e 3952. Algumas características são seu \textit{sample rate} de 8 kHz e seu \textit{bitrate} de 13.33 kbps ou 15.2kbps. Segundo \cite{ilbc}, a qualidade básica do áudio usando iLBC é maior que a oferecida pelo ITU-T G.729A.	
	
	
\subsection{Padrões para Codificação de Vídeo}\label{sec:codecs-video}

	
	\subsubsection{\textbf{Padrão H.26x}}\label{sec:h26x}
		
		Codecs H.26x são padrões ITU-T para video. No contexto de videoconferência, destacam-se:
		
		\begin{itemize}
			\item \textbf{H.261}: Usado para interoperação com \textit{endpoints} antigos (\textit{legacy}). Vídeos H.261 podem ser QCIF (resolução de 176x144) a 30 \textit{fps} ou CIF (352x288) a 15 \textit{fps} \cite{h.261-rfc}.
			
			\item \textbf{H.263}: Existem 3 versões para H.263: \textit{Base} H.263 (ou, simplesmente, H.263), H.263+ ou H.263-1998 (que também engloba as características do H.263) e H.263++ ou H.263-2000 (também englobando as características do H.263-1998). 
			
			H.263 define as seguintes resoluções: sub-QCIF (128x96), QCIF, CIF, CIF4 (704x576), CIF16 (1056x864) e CUSTOM (personalizável - largura e altura devem ser múltiplos de 4).
			
			H.263 e H.263-1998, que não suportam \textit{profiles} e \textit{levels}, utilizam, por default,  QCIF a 30 \textit{fps} (podendo utilizar outros valores através de negociações SIP ou H.323).
			
			H.263-2000 apresenta 9 perfis de vídeo e múltiplos \textit{levels}, que definem quais os \textit{bitrates}, \textit{fps} e resoluções permitidas. Para videoconferência, o profile recomendado é o \textit{baseline} (\textit{profile} 0), que é o perfil 'mínimo' (sem as \textit{features} adicionais e opções de operação de outros perfis).	
			
			\item \textbf{H.264}: Sucessor do H.263. Foi desenvolvido em conjunto com a ISO/IEC, sendo também conhecido como AVC (\textit{Advanced Video Codec}). Gera de 30 a 50\% menos \textit{bitrate} que H.263, embora aumente o uso de CPU - pode demandar 3 ou 4 vezes mais processamento que outros codecs de vídeo \cite{conferencingFundamentals}, dependendo do \textit{profile} usado na codificação H.264.
		
		    O perfil H.264 para videoconferência é o \textit{baseline}. \textit{Levels} válidos são: 1, 1.1, 1.2, 1.3, 2, 2.1, 2.2, 3, 3.1, 3.2, 4, 4.1, 4.2, 5, e 5.1. Por exemplo, o level 3.0 define 4CIF a 25 fps. É possível consultar a lista completa de \textit{levels} e suas definições em \cite{h264-recommendation}.
		\end{itemize}
		
		
	\subsubsection{\textbf{Padrão VPx}}\label{sec:vpx}
		
		O padrão de codificação VPx foi desenvolvida pela On2 Technologies, originado da série de codecs \textit{True Motion}. O primeiro padrão VPx foi o \textit{True Motion} VP3, sucessor do \textit{TrueMotion} RT 2.0.
		
		Em 2010, a On2 Technologies foi adquirida pela Google\footnote{\url{http://www.on2.com/}} e, assim, o padrão VP8, que fora publicado em 2008, tornou-se público através do WebM Project\footnote{\url{http://www.webmproject.org/about/}}, sendo posteriormente incorporado ao pacote de mídia do WebRTC\footnote{\url{https://webrtc.org/faq/#what-is-the-vp8-video-codec}}.
		
		O codec VP8 define 4 \textit{profiles} e 3 \textit{levels} \cite{VP8} que, diferentemente da definição convencional - explicado e exemplificado anteriormente - apenas regulam a complexidade do processo de decodificação/descompressão dos dados de vídeo.
		
		

	
	
		
\section{Tecnologias para Webconferência}\label{sec:tecnologias-webconf}

    
\subsection{Plataforma Flash}\label{sec:flash}

    Adobe Flash (anteriormente Macromedia Flash) é uma plataforma de desenvolvimento de software para desktop, mobile e navegadores web. Na Figura~\ref{fig:adobe-arch}, temos a visão geral da sua arquitetura.
    
  		 \begin{figure}[h]
  			\centering
  			\includegraphics[width=34em, height=25em]{img/adobe-arch.jpg}
  			\caption{Visão geral da arquitetura da plataforma Flash.}
  			\label{fig:adobe-arch}
  		 \end{figure}
  		 
  	 O desenvolvimento de aplicações Flash se dá através da linguagem de programação ActionScript\footnote{\url{http://www.adobe.com/devnet/actionscript.html}} e, para a confecção de interfaces de usuário, da linguagem de marcação MXML\footnote{\url{http://help.adobe.com/en_US/flex/using/WS2db454920e96a9e51e63e3d11c0bf5f39f-7fff.html}}, ambas integradas no framework Flex\footnote{\url{http://www.adobe.com/br/products/flex.html}}. Para administrar os projetos de código que utilizam tal framework, há a IDE Flex Builder\footnote{\url{http://www.adobe.com/br/products/flash-builder.html}}, renomeada posteriormente para \textit{Flash Builder} e exclusiva para Windows. O software Adobe Air\footnote{\url{http://www.adobe.com/br/products/air.html}} permite que o mesmo código seja executado em diferentes sistemas operacionais (Windows, Linux, Mac, Android, Mac OS, entre outros).
  	    	
     É através do software Flash Player que navegadores web podem, por meio da instalação do plugin, reproduzir conteúdo multimídia. Devido sua facilidade de uso, logo tornou-se um padrão popular para \textit{streaming} de áudio e vídeo na web. Entre os famosos provedores de conteúdo que utilizam ou já utilizaram o Flash Player, destacam-se Spotify, Yahoo, BBC Online, Youtube, entre outros.
     
     Sistemas de webconferência desenvolvidas sobre a plataforma Flash devem usar os padrões suportados pelo Flash Player que, no contexto de videoconferência, define o seguinte escopo:
		
		\begin{itemize}
		   \item Transporte de mídia: RTMP;
		   \item Codecs de áudio: Speex e G.711 (PCMA e PCMU);
		   \item Codecs de vídeo: H.263, H.264 e VP6.
		\end{itemize}
		
	Depende-se de um servidor de mídia Flash para a distribuição de áudio e vídeo entre múltiplos clientes Flash. A conexão destes com o servidor se dá através de um \textit{NetConnection}, definida na API do ActionScript. O servidor de mídia Flash também pode conectar usuários externos (não-Flash) que utilizam SIP, já que o Flash Player por si só não define Plano de Controle. Servidores de mídia Flash conhecidos são o Adobe Media Server\footnote{\url{http://www.adobe.com/br/products/adobe-media-server-family.html}} (ilustrado na Figura~\ref{fig:adobe-arch} como \textit{Flash Media Server}) e o Red5 (que veremos no próximo capítulo).

\subsection{WebRTC}\label{sec:webrtc}
	
	WebRTC é um framework aberto que provê capacidades de comunicação em tempo real para navegadores web, implementando componentes que dão suporte a chat, áudio e vídeo, sem a necessidade de instalação de plugins. Desenvolvedores que desejam utilizar WebRTC para construir um sistema de webconferência podem acessar tais componentes pela Web API, que utiliza JavaScript. À época deste trabalho, WebRTC é suportado pelos navegadores web Chrome, Firefox e Opera, e está em processo de se tornar um padrão IETF.
		
	A arquitetura geral do WebRTC é apresentada Figura~\ref{fig:webrtc-arch}.
	
  		 \begin{figure}[h]
  			\centering
  			\includegraphics[width=35em, height=20em]{img/webrtc-arch.png}
  			\caption{Visão geral da arquitetura do WebRTC.}
  			\label{fig:webrtc-arch}
  		 \end{figure}
  	
  	A camada em verde é a camada implementada pelos navegadores web. Eles devem prover a camada RTP e a implementação dos codecs de mídia. Navegadores web devem, no mínimo, implementar VP8, OPUS, iSAC e iLBC. Chrome e Firefox ainda oferecem suporte a H.264. 
  	
    A conexão entre clientes WebRTC se dá através de um \textit{WebSocket}, tecnologia que utiliza TCP para conectar navegadores web. Assim como o Flash Player, WebRTC não define Plano de Controle. A filosofia do WebRTC é deixar a escolha do uso do protocolo de sinalização para a aplicação web, enquanto o navegador web fica responsável pelo Plano de Mídia. Entretanto, o próprio WebRTC faz recomendações de bibliotecas web que implementam SIP, como o JsSIP\footnote{\url{http://www.jssip.net/}} e o SIP.js\footnote{\url{http://sipjs.com/}}, ambas implementadas em Java-\\Script. Assim, um cliente WebRTC tem a capacidade de fazer ligações para \textit{endpoints} ou servidores SIP.
    
    Informações adicionais sobre WebRTC é possível acessando o webrtc.org\footnote{\url{https://webrtc.org/}}.